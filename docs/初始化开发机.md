# 初始化文档

## 初始化用户

**创建用户**

```
useradd dougzheng
passwd dougzheng
```

**配置免密 sudo**

先 `chmod u+w /etc/sudoers` ，

然后 `vim /etc/sudoers` ，添加一行：

```
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
dougzheng ALL=(ALL) NOPASSWD:ALL # 添加的行
```

最后 `chmod u-w /etc/sudoers` 。

## hadoop 使用

**hosts 配置**

登录一台机器作为 master 进行配置。

`vim /etc/hostname` 修改主机名。

`vim /etc/hosts` 中添加 ip 和主机名映射，即 `hadoop101, hadoop102, hadoop103` 的 ip 。

`ping hadoop101` 检查是否生效。

**免密登录配置**

依然在家目录 `.ssh` 目录下进行。

```
ssh-keygen # 一路回车，默认即可
ssh-copy-id hadoop101
ssh-copy-id hadoop102
ssh-copy-id hadoop103
```

**安装 jdk**

安装切到 root 进行。

`scp hadoop.zip username@ip:path` 上传本地的 `hadoop.zip` 压缩包。

`yum install unzip` 安装解压命令然后 `unzip hadoop.zip` 。

安装 jdk ：

```
mkdir /usr/local/jdk
tar -zxvf jdk-8u211-linux-x64.tar.gz -C /usr/local/jdk # 解压到 /usr/local/jdk
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export JAVA_HOME=/usr/local/jdk/jdk1.8.0_211
export PATH=$JAVA_HOME/bin:$PATH
```

`source /etc/profile` 生效后，`java -version` 查看版本。

最后使用 `scp` 同步配置到其他主机。 

**安装 zookeeper**

```
mkdir /usr/local/zookeeper
tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/zookeeper
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export ZK_HOME=/usr/local/zookeeper/apache-zookeeper-3.5.7-bin
export PATH=$ZK_HOME/bin:$PATH
```

创建 `zkData` 目录和 `myid` ：

```
mkdir -p /data0/zkData
cd /data0/zkData/
touch myid
echo 1 > myid # hadoop101写入1，hadoop102写入2，...
chown -R dougzheng:dougzheng /data0
```

配置 `zoo.cfg` ：

```
cd $ZK_HOME/conf
cp zoo_sample.cfg zoo.cfg
vim zoo.cfg
```

在 `zoo.cfg` 中作如下修改：

```
dataDir=/data0/zkData # 修改dataDir
# 新增以下配置
server.1=0.0.0.0:2888:3888 # hadoop1机器上改为0.0.0.0，hadoop102则改server.2，...
server.2=hadoop102:2888:3888
server.3=hadoop103:2888:3888
```

修改权限：

```
chown -R dougzheng:dougzheng $ZK_HOME
```

最后同步修改所有主机。

**启动 zookeeper**

`su - dougzheng` 切换用户。

在各主机上分别运行 `zkServer.sh start` ，最后 `zkServer.sh status` 查看启动状态，应有 1 个 leader 、2 个 follower 。

可运行 `zkServer.sh start-foreground` 查看运行日志。

**HDFS HA 搭建**

```
mkdir /usr/local/hadoop
tar -zxvf hadoop-3.1.3.tar.gz -C /usr/local/hadoop
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export HADOOP_HOME=/usr/local/hadoop/hadoop-3.1.3
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```

配置 `$HADOOP_HOME/etc/hadoop/` 下的 `hdfs-site.xml` 、`core-site.xml` 、 `yarn-site.xml` 和 `workers` 。

配置 `$HADOOP_HOME/sbin/` 下的 `start-dfs.sh` 、`stop-dfs.sh` 、`start-yarn.sh` 和 `stop-yarn.sh` 。

在 `$HADOOP_HOME/etc/hadoop/hadoop-env.sh` 中加入 `JAVA_HOME` 环境变量。

修改权限：

```
chown -R dougzheng:dougzheng $HADOOP_HOME 
```

最后分发文件到各机器上。

**启动集群**

删除残余文件：

```
rm -rf /usr/local/hadoop/hadoop-3.1.3/logs && rm -rf /tmp/hadoop* && rm -rf /data0/dfs
```

首先在全部机器上启动 `journalnode` ：

```
hdfs --daemon start journalnode
```

在 `nn1` 上格式化 `namenode` ：

```
hdfs namenode -format
```

在 `nn1` 上启动 `namenode` ：

```
hdfs --daemon start namenode
```

在其他机器上同步 `nn1` 并启动 `namenode` ：

```
hdfs namenode -bootstrapStandby && hdfs --daemon start namenode
```

关闭所有 hdfs 服务：

```
stop-all.sh
```

初始化 HA 在 zookeeper 中状态：

```
hdfs zkfc -formatZK
```

启动集群服务：

```
start-all.sh
```

## hive 使用

**安装 mysql**

切换到 root 操作。

```
yum remove mysql-libs
yum install libaio
yum install autoconf
rpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm
```

`systemctl start mysqld` 启动 mysql 服务。

`cat /var/log/mysqld.log | grep password` 查看 mysql 初始密码。

**配置 mysql**

`mysql -u root -p` ，输入密码，登录 mysql 。

配置新密码：

```
set global validate_password_length=4;
set global validate_password_policy=0;
set password=password("000000");
```

配置 host ：

```
use mysql
select user, host from user;
update user set host="%" where user="root";
flush privileges;
```

配置新用户：

```
create user 'dougzheng'@'%' identified by 'typeyourpassword';
GRANT ALL ON *.* TO 'dougzheng'@'%';
```

**安装 hive**

```
mkdir /usr/local/hive
tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /usr/local/hive
```

配置环境变量，在 `/etc/profile` 下面添加：

```
# hive
export HIVE_HOME=/usr/local/hive/apache-hive-3.1.2-bin
export PATH=$HIVE_HOME/bin:$PATH
```

解决 jar 包冲突：

```
mv $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar.bak
rm $HIVE_HOME/lib/guava*.jar && cp $HADOOP_HOME/share/hadoop/common/lib/guava*.jar $HIVE_HOME/lib/
```

拷贝 jdbc 驱动：

```
cp /opt/software/mysql-connector-java-5.1.48.jar $HIVE_HOME/lib
```

配置 `hive-site.xml` ：

```
vim $HIVE_HOME/conf/hive-site.xml # 内容略
```

**启动 hive**

新建 hive 元数据库：

```
mysql -u dougzheng -p
create database metastore;
```

修改权限：

```
chown -R dougzheng:dougzheng $HIVE_HOME
```

初始化 hive 元数据库：

```
su - dougzheng
schematool -initSchema -dbType mysql -verbose
```

查看 hive 数据库：

```
hive
show databases;
```

## shell 脚本

**文件分发**

e.g. `./xsync.sh /usr/local/hadoop` 

```
#!/bin/bash
ips=(hadoop101 hadoop102 hadoop103)
for ip in ${ips[@]}
do
  for file in $@
    do          
      if [[ -e $file ]] 
      then      
        pdir=$(cd -P $(dirname $file); pwd)
        fname=$(basename $file) 
        ssh $ip "mkdir -p $pdir"
        rsync -av $pdir/$fname $ip:$pdir
        echo $pdir              
      else      
        echo $file does not exists! 
      fi      
    done        
done
```

**hadoop 格式化**

e.g. `./format.sh` 

```
#!/bin/bash
ips=(hadoop101 hadoop102 hadoop103)

for ip in ${ips[@]}
do
ssh -T $ip <<EOF
rm -rf $HADOOP_HOME/logs /tmp/hadoop* /data0/dfs
EOF
done

for ip in ${ips[@]}
do
ssh -T $ip <<EOF
hdfs --daemon start journalnode
EOF
done

ssh -T ${ips[0]} <<EOF
hdfs namenode -format <<YON
Y
YON
hdfs --daemon start namenode
EOF

ssh -T ${ips[1]} <<EOF
hdfs namenode -bootstrapStandby
hdfs --daemon start namenode
EOF

ssh -T ${ips[2]} <<EOF
hdfs namenode -bootstrapStandby
hdfs --daemon start namenode
EOF

ssh -T ${ips[0]} <<EOF
stop-all.sh
hdfs zkfc -formatZK <<YON
Y
Y
YON
start-all.sh
EOF
```

e.g. `./zk.sh start` 、`./zk.sh status` 

**zookeeper 启动/关闭**

```
#!/bin/bash
ips=(hadoop101 hadoop102 hadoop103)
cmd=$1
[[ $cmd == status ]] && out=/dev/stdout || out=/dev/null
echo command is $cmd
for ip in ${ips[@]}
do
echo remote to $ip.
ssh $ip >$out 2>&1 <<EOF
    cd
    zkServer.sh $cmd
    exit
EOF
done
echo command done.
```



