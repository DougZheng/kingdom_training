# 初始化文档

## 初始化用户

### 创建用户

```
useradd dougzheng
passwd dougzheng
```

### 配置免密 sudo

先 `chmod u+w /etc/sudoers` ，

然后 `vim /etc/sudoers` ，添加一行：

```
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
dougzheng ALL=(ALL) NOPASSWD:ALL # 添加的行
```

最后 `chmod u-w /etc/sudoers` 。

## hadoop 使用

### hosts 配置

登录一台机器作为 master 进行配置。

`vim /etc/hostname` 修改主机名。

`vim /etc/hosts` 中添加 ip 和主机名映射，即 `hadoop101, hadoop102, hadoop103` 的 ip 。

`ping hadoop101` 检查是否生效。

### 免密登录配置

依然在家目录 `.ssh` 目录下进行。

```
ssh-keygen # 一路回车，默认即可
ssh-copy-id hadoop101
ssh-copy-id hadoop102
ssh-copy-id hadoop103
```

### 安装 jdk

安装切到 root 进行。

`scp hadoop.zip username@ip:path` 上传本地的 `hadoop.zip` 压缩包。

`yum install unzip` 安装解压命令然后 `unzip hadoop.zip` 。

安装 jdk ：

```
mkdir /usr/local/jdk
tar -zxvf jdk-8u211-linux-x64.tar.gz -C /usr/local/jdk # 解压到 /usr/local/jdk
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export JAVA_HOME=/usr/local/jdk/jdk1.8.0_211
export PATH=$JAVA_HOME/bin:$PATH
```

`source /etc/profile` 生效后，`java -version` 查看版本。

最后使用 `scp` 同步配置到其他主机。 

### 安装 zookeeper

```
mkdir /usr/local/zookeeper
tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/zookeeper
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export ZK_HOME=/usr/local/zookeeper/apache-zookeeper-3.5.7-bin
export PATH=$ZK_HOME/bin:$PATH
```

创建 `zkData` 目录和 `myid` ：

```
mkdir -p /data0/zkData
cd /data0/zkData/
touch myid
echo 1 > myid # hadoop101写入1，hadoop102写入2，...
chown -R dougzheng:dougzheng /data0
```

配置 `zoo.cfg` ：

```
cd $ZK_HOME/conf
cp zoo_sample.cfg zoo.cfg
vim zoo.cfg
```

在 `zoo.cfg` 中作如下修改：

```
dataDir=/data0/zkData # 修改dataDir
# 新增以下配置
server.1=hadoop101:2888:3888
server.2=hadoop102:2888:3888
server.3=hadoop103:2888:3888
```

修改权限：

```
chown -R dougzheng:dougzheng $ZK_HOME
```

最后同步修改所有主机。

### 启动 zookeeper

`su - dougzheng` 切换用户。

在各主机上分别运行 `zkServer.sh start` ，最后 `zkServer.sh status` 查看启动状态，应有 1 个 leader 、2 个 follower 。

可运行 `zkServer.sh start-foreground` 查看运行日志。

### HDFS HA 搭建

```
mkdir /usr/local/hadoop
tar -zxvf hadoop-3.1.3.tar.gz -C /usr/local/hadoop
```

配置环境变量，在 `/etc/profile` 下面添加：

```
export HADOOP_HOME=/usr/local/hadoop/hadoop-3.1.3
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```

配置 `$HADOOP_HOME/etc/hadoop/` 下的 `hdfs-site.xml` 、`core-site.xml` 、 `yarn-site.xml` 和 `workers` 。

配置 `$HADOOP_HOME/sbin/` 下的 `start-dfs.sh` 、`stop-dfs.sh` 、`start-yarn.sh` 和 `stop-yarn.sh` 。

在 `$HADOOP_HOME/etc/hadoop/hadoop-env.sh` 中加入 `JAVA_HOME` 环境变量。

修改权限：

```
chown -R dougzheng:dougzheng $HADOOP_HOME 
```

最后分发文件到各机器上。

### 启动集群

删除残余文件：

```
rm -rf /usr/local/hadoop/hadoop-3.1.3/logs && rm -rf /tmp/hadoop* && rm -rf /data0/dfs
```

首先在全部机器上启动 `journalnode` ：

```
hdfs --daemon start journalnode
```

在 `nn1` 上格式化 `namenode` ：

```
hdfs namenode -format
```

在 `nn1` 上启动 `namenode` ：

```
hdfs --daemon start namenode
```

在其他机器上同步 `nn1` 并启动 `namenode` ：

```
hdfs namenode -bootstrapStandby && hdfs --daemon start namenode
```

关闭所有 hdfs 服务：

```
stop-all.sh
```

初始化 HA 在 zookeeper 中状态：

```
hdfs zkfc -formatZK
```

启动集群服务：

```
start-all.sh
```

### 跨集群拷贝

`vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml` ，添加以下配置：

```
<property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>true</value>
</property>
```

这个配置在于让服务端 namenode 返回 datanode 节点的主机名而非 ip ，若不配置则服务端 namenode 会返回 datanode 的内网 ip ，客户端无法访问，进而连接超时。

再 `vim /etc/hosts` ，添加服务端（ip，主机名 ）映射：

```
159.75.xxx.xxx   doug-hadoop101  doug-hadoop101
159.75.xxx.xxx   doug-hadoop102  doug-hadoop102
159.75.xxx.xxx   doug-hadoop103  doug-hadoop103
```

这一步使得客户端能够解析服务端返回的 datanode 的主机名，访问 datanode 的公网地址（服务端需开放 namenode 控制访问 8020 端口，以及 datanode 数据传输 9866 端口）。

最后，集群间拷贝数据：

```
hadoop distcp hdfs://doug-hadoop101:8020/test.txt /test_download.txt
```

## hive 使用

### 安装 mysql

切换到 root 操作。

```
yum remove mysql-libs
yum install libaio
yum install autoconf
rpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm
rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm
```

`systemctl start mysqld` 启动 mysql 服务。

`cat /var/log/mysqld.log | grep password` 查看 mysql 初始密码。

### 配置 mysql

`mysql -u root -p` ，输入密码，登录 mysql 。

配置新密码：

```
set global validate_password_length=4;
set global validate_password_policy=0;
set password=password("000000");
```

配置 host ：

```
use mysql
select user, host from user;
update user set host="%" where user="root";
flush privileges;
```

配置新用户：

```
create user 'dougzheng'@'%' identified by 'typeyourpassword';
GRANT ALL ON *.* TO 'dougzheng'@'%';
```

### 安装 hive

```
mkdir /usr/local/hive
tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /usr/local/hive
```

配置环境变量，在 `/etc/profile` 下面添加：

```
# HIVE
export HIVE_HOME=/usr/local/hive/apache-hive-3.1.2-bin
export PATH=$HIVE_HOME/bin:$PATH
```

解决 jar 包冲突：

```
mv $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar.bak
rm $HIVE_HOME/lib/guava*.jar && cp $HADOOP_HOME/share/hadoop/common/lib/guava*.jar $HIVE_HOME/lib/
```

拷贝 jdbc 驱动：

```
cp /opt/software/mysql-connector-java-5.1.48.jar $HIVE_HOME/lib
```

配置 `hive-site.xml` ：

```
vim $HIVE_HOME/conf/hive-site.xml # 内容略
```

### 启动 hive

新建 hive 元数据库：

```
mysql -u dougzheng -p
create database metastore;
```

修改权限：

```
chown -R dougzheng:dougzheng $HIVE_HOME
```

初始化 hive 元数据库：

```
su - dougzheng
schematool -initSchema -dbType mysql -verbose
```

查看 hive 数据库：

```
hive
show databases;
```

### 配置 hive

修改日志存放目录：

```
mv $HIVE_HOME/conf/hive-log4j2.properties{.template,}
```

`vim hive-log4j.properties` ，修改 `hive.log.dir` 属性。

## kafka 使用

### 安装 kafka

```
mkdir /usr/local/kafka
tar -zxvf kafka_2.11-2.4.1.tgz -C /usr/local/kafka
```

配置环境变量，在 `/etc/profile` 下面添加：

```
# KAFKA
export KAFKA_HOME=/usr/local/kafka/kafka_2.11-2.4.1
export PATH=$KAFKA_HOME/bin:$PATH
```

创建 `logs` 文件夹：

```
source /etc/profile
mkdir $KAFKA_HOME/logs
```

`vim $KAFKA_HOME/config/server.properties` 修改配置：

```
#broker的全局唯一编号，不能重复
broker.id=0
#删除topic功能使能（新增）
delete.topic.enable=true
#kafka运行日志存放的路径
log.dirs=/data0/kafka-logs
#配置连接Zookeeper集群地址
zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181/kafka
```

修改权限：

```
chown -R dougzheng:dougzheng $KAFKA_HOME
```

最后在其他机器上同步安装，修改 `broker.id` 。

### 启动 kafka

启动：

```
kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
```

关闭：

```
kafka-server-stop.sh
```

### 配置 kafka eagle

`vim $KAFKA_HOME/bin/kafka-server-start.sh` ，修改：

```
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-server -Xms1G -Xmx1G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"
    export JMX_PORT="9999"
    #export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G" # 删除
fi
```

安装：

```
mkdir /usr/local/kafka-eagle
tar -zxvf kafka-eagle-bin-1.3.7.tar.gz .
tar -zxvf kafka-eagle-bin-1.3.7/kafka-eagle-web-1.3.7-bin.tar.gz -C /usr/local/kafka-eagle
```

配置环境变量，在 `/etc/profile` 下面添加：

 ```
# KAFKA-EAGLE
export KE_HOME=/usr/local/kafka-eagle/kafka-eagle-web-1.3.7
export PATH=$KE_HOME/bin:$PATH
 ```

`ke.sh` 添加执行权限：

```
chmod +x $KE_HOME/bin/ke.sh
```

`vim $KE_HOME/conf/system-config.properties` 修改配置文件：

```
######################################
# multi zookeeper&kafka cluster list
######################################
kafka.eagle.zk.cluster.alias=cluster1
cluster1.zk.list=hadoop101:2181,hadoop102:2181,hadoop103:2181/kafka

######################################
# kafka offset storage
######################################
cluster1.kafka.eagle.offset.storage=kafka

######################################
# enable kafka metrics
######################################
kafka.eagle.metrics.charts=true
kafka.eagle.sql.fix.error=false

######################################
# kafka jdbc driver address
######################################
kafka.eagle.driver=com.mysql.jdbc.Driver
kafka.eagle.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
kafka.eagle.username=dougzheng
kafka.eagle.password=000000
```

修改权限：

```
chown -R dougzheng:dougzheng /usr/local/kafka-eagle
```

启动：

```
ke.sh start
```

登录监控平台：

```
http://ip:8048/ke
```

## flume 使用

### 安装 flume

```
mkdir /usr/local/flume
tar -zxvf apache-flume-1.9.0-bin.tar.gz -C /usr/local/flume
```

配置环境变量，在 `/etc/profile` 下面添加：

```
# FLUME
export FLUME_HOME=/usr/local/flume/apache-flume-1.9.0-bin
export PATH=$FLUME_HOME/bin:$PATH
```

删除 `guava-11.0.2.jar` 以兼容 hadoop3.1.3 ：

```
rm $FLUME_HOME/lib/guava-11.0.2.jar
```

配置 `flume-env.sh` ：

```
mv $FLUME_HOME/conf/flume-env.sh{.template,}
echo "export JAVA_HOME=$JAVA_HOME" >> $FLUME_HOME/conf/flume-env.sh
```

修改权限：

```
chown -R dougzheng:dougzheng $FLUME_HOME
```

## sqoop 使用

## superset 使用

## azkaban 使用

## spark 使用

咕了。